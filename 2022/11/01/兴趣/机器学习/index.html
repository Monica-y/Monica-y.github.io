<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"monica-y.github.io","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="机器学习笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习">
<meta property="og:url" content="https://monica-y.github.io/2022/11/01/%E5%85%B4%E8%B6%A3/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="机器学习笔记">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://monica-y.github.io/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A01.png">
<meta property="og:image" content="https://monica-y.github.io/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A02.png">
<meta property="og:image" content="https://monica-y.github.io/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A03.png">
<meta property="og:image" content="https://monica-y.github.io/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A01.png">
<meta property="og:image" content="https://monica-y.github.io/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E6%8F%8F%E8%BF%B01.png">
<meta property="og:image" content="https://monica-y.github.io/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B02.png">
<meta property="og:image" content="https://monica-y.github.io/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B03.png">
<meta property="og:image" content="https://monica-y.github.io/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B04.png">
<meta property="og:image" content="https://monica-y.github.io/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B05.png">
<meta property="article:published_time" content="2022-11-01T11:03:16.175Z">
<meta property="article:modified_time" content="2022-11-02T15:14:43.242Z">
<meta property="article:author" content="Monica">
<meta property="article:tag" content="数据挖掘">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://monica-y.github.io/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A01.png">

<link rel="canonical" href="https://monica-y.github.io/2022/11/01/%E5%85%B4%E8%B6%A3/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>机器学习 | Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://monica-y.github.io/2022/11/01/%E5%85%B4%E8%B6%A3/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Monica">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-11-01 19:03:16" itemprop="dateCreated datePublished" datetime="2022-11-01T19:03:16+08:00">2022-11-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-11-02 23:14:43" itemprop="dateModified" datetime="2022-11-02T23:14:43+08:00">2022-11-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" itemprop="url" rel="index"><span itemprop="name">数据挖掘</span></a>
                </span>
            </span>

          
            <div class="post-description">机器学习笔记</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><a href="https://github.com/TheisTrue/MLofAndrew-Ng/tree/master/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AE%B2%E4%B9%89" target="_blank" rel="noopener">讲义地址</a></p>
<h2 id="1-什么是机器学习"><a href="#1-什么是机器学习" class="headerlink" title="1 什么是机器学习"></a>1 什么是机器学习</h2><h3 id="1-1-机器学习的定义"><a href="#1-1-机器学习的定义" class="headerlink" title="1.1 机器学习的定义"></a>1.1 机器学习的定义</h3><p>Arthur Samuel:在没有明确编程(设置)的情况下，使计算机具有学习能力的研究领域。<br>Tom Mitchell：如果一个计算机程序可以通过经验E使得其在处理任务T时获得更好的效果(这个效果的好坏用性能度量P来衡量),即通过P测定在T上的表现因E而提高。<br>对于机器人跳棋程序来说，经验E就是程序与人下几万次跳棋，任务T就是玩跳棋，性能度量就是与新对手玩跳棋时赢的概率。<br>对于垃圾邮件拦截程序来说，经验E就是观察人对不同邮件的分类，任务T就是将邮件分类为垃圾邮件和非垃圾邮件，性能度量就是正确归类的邮件比例。</p>
<h3 id="1-2-学习算法"><a href="#1-2-学习算法" class="headerlink" title="1.2 学习算法"></a>1.2 学习算法</h3><p>1 监督学习(supervised learning),主要思想就是我们会教计算机做某件事情。<br>2 无监督学习(unsupervised learning)，主要思想是让计算机自己学习。<br>其他热词：强化学习(reinforcement)，推荐系统(recommender system)<br>要点：在应用学习算法的实际建议。如果我想要开发机器学习系统，如何让那些最佳实践操作指导我的决定，用什么方式建立自己的系统。</p>
<h2 id="2-监督学习"><a href="#2-监督学习" class="headerlink" title="2 监督学习"></a>2 监督学习</h2><h3 id="2-1-回归问题"><a href="#2-1-回归问题" class="headerlink" title="2.1 回归问题"></a>2.1 回归问题</h3><p>假设我要预测房价，我收集到了一些现有的房价数据。想要知道750平米的房子的价格是多少呢？学习算法能做的一件事情就是根据数据画一条直线，或者说用一条直线拟合数据(粉色直线)。然后可以估计出房子的价值约为150k。除了用一条直线拟合数据，可以用二次函数或二阶多项式(蓝色曲线)。然后可以估计出房子的价值约为200k。<br><img src="/images/机器学习/监督学习1.png" alt="监督学习1"><br>监督学习是指我们给算法一个数据集，其中包含了正确答案。也就是说我们给它一个房价数据集，在这个数据集中的每个样本，我们都给出正确的价格，即这个房子实际卖价。算法的目的就是给出更多的正确答案。例如得到面积为750的房子的价格。<br>用更专业的术语来定义，它也被称为回归问题。这里的回归问题指的是我们想要预测连续的数值输出，也就是房子的价格。在技术上来说，价格可以精确到分，因此实际上是一个离散值，但通常我们认为房价是一个实数，即连续值。回归这个术语是指我们设法预测连续值的属性。</p>
<h3 id="2-2-分类问题"><a href="#2-2-分类问题" class="headerlink" title="2.2 分类问题"></a>2.2 分类问题</h3><p>假设我想看医疗记录并设法预测乳腺癌是恶性的还是良性的。假设某人发现了一个乳腺肿瘤，即乳房上的肿块，恶性肿瘤就是有害且危险的，良性肿瘤就是无害的。<br>假设在我的数据集中，横轴是肿瘤的尺寸，纵轴表示我们看到的肿瘤样本是否是恶性的。然后有一个肿瘤样本的大小位于粉色箭头处，我们想要估计出肿瘤是良性还有恶性的概率。这就是一个分类问题。<br>分类问题就是我们设法预测一个离散值输出。对于这个问题，就是输出是0还是1。实际上在分类问题中，有时也可以有两个以上的可能的输出值。在实际例子中就是，可能有三种类型的乳腺癌，因此，可能的输出就有0(良性)，1(癌症类型1)，2(癌症类型2)和3(癌症类型3)。<br><img src="/images/机器学习/监督学习2.png" alt="监督学习2"><br>在分类问题中，有另一种方法来绘制这些数据。如果肿瘤的大小是预测恶性或良性的特征，我们可以在一个坐标轴上(表示肿瘤大小的坐标轴)，用不同的符号来表示良性或恶性(第二行的图)。在这个例子中，我们只使用了一个特征(属性)，即肿瘤得大小。在其他得机器学习问题中，我们会有多个特征(属性)。假设我们不仅知道肿瘤的大小，还知道病人的年纪，在这种情况下的数据集可以表示为下图。如果有一个患者，他的情况位于图中粉点处。因此在给定的数据集上，学习算法能做的，就是在数据上画出一条直线(黑色直线)，设法将恶性瘤和良性瘤分开，算法可以通过这条直线判断肿瘤的类型。在这个例子中，我们有两种特征，即病人的年龄和肿瘤大小。在其他的机器学习算法中，往往会有更多的特征，例如肿块的厚度，肿瘤细胞大小的均匀性，肿瘤细胞形状的均匀性。<br><img src="/images/机器学习/监督学习3.png" alt="监督学习3"><br>最有趣的机器学习算法，是一个不仅仅能处理两到三个或五个特征，而是能处理无穷多特征的算法，即如何在计算机中存储无穷维度的数据，而不会溢出呢？以支持向量机算法为例，就有一个灵活的数学技巧，允许计算机处理无穷多的特征。</p>
<h3 id="2-3-总结"><a href="#2-3-总结" class="headerlink" title="2.3 总结"></a>2.3 总结</h3><p>在这节课上我们讨论了监督学习，想法是在监督学习中，对于数据集中的每个样本，我们想要算法预测，并得出“正确答案”。像是房子的价格，或肿瘤是恶性还是良性的。<br>我们也讨论了回归问题，回归是指我们的目标是预测一个连续值输出。<br>我们还讨论了分类问题，其目的是预测离散值输出。</p>
<h2 id="3-无监督学习"><a href="#3-无监督学习" class="headerlink" title="3 无监督学习"></a>3 无监督学习</h2><h3 id="3-1-聚类"><a href="#3-1-聚类" class="headerlink" title="3.1 聚类"></a>3.1 聚类</h3><p>在上一节的监督学习中，我们的数据集中每个样本都被标明为阳性样本或阴性样本，即良性或恶性肿瘤。对于监督学习中的每个样本，我们已经被清楚地告知了什么是所谓的正确答案，即它们是良性还是恶性。在无监督学习中，我们所用的数据集中没有任何标签，我们试图在其中找到某种结构。无监督学习可能判定该数据集包含两个不同的簇。无监督学习算法，可以把这些数据分成两个不同的簇，这就是聚类算法。<br><img src="/images/机器学习/无监督学习1.png" alt="无监督学习1"><br>一个应用聚类算法的例子就是谷歌新闻。谷歌新闻所做的就是每天去网络上收集几十万条新闻，然后将它们组成一个个新闻专题。本质上就是将它们分簇，有关同一主题的新闻，被显示在一起。<br>其实聚类算法和无监督学习算法，也可以用于基因检测中。基因检测用于测定特定基因的表达程度，我们可以对测序结果进行聚类。<br>无监督学习或聚类算法可以用来组织大型的计算机集群。尝试找到那些机器趋向于协同工作，如果在实际使用中让这些机器共同工作，则数据中心可以更高效地工作。<br>聚类算法可以用于社交网络分析。如果可以得到我Email最频繁地联系人，机器就可以自动识别同属于一个圈子的朋友，判断哪些人互相认识。<br>聚类算法可以用于市场分析。许多公司利用庞大的客户信息数据库，对客户进行分类，从而能够自动高效地使用不同地策略进行销售。<br>聚类算法可以被用于天文数据分析，用于星系形成理论的研究。</p>
<h3 id="3-2-鸡尾酒会算法"><a href="#3-2-鸡尾酒会算法" class="headerlink" title="3.2 鸡尾酒会算法"></a>3.2 鸡尾酒会算法</h3><p>聚类算法只是无监督学习的一种。<br>鸡尾酒会问题。有一个宴会，有一屋子的人，大家都坐在一起说话，因为每个人都同时在说话，有许多声音混杂在一起，几乎很难听清楚面前的人说话。假设一个鸡尾酒会上只有两个人，也就是只有两个人在同时说话。我们放下了两个麦克风来记录来自两人声音的不同组合。两个人在两个麦克风的记录中声音大小不同，但是都是两个人话语重合的声音。<br>我们把这两个声音交给鸡尾酒会算法，让它帮忙找出数据的结构。鸡尾酒会算法会分离出这两个被叠加到一起的声音。或者是说话的声音和背景音。算法的主要代码为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[W,s,v] &#x3D; svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x&#39;);</span><br></pre></td></tr></table></figure>
<p>在课程中使用的代码为Octave。svd函数全称为奇异值分解函数。</p>
<h2 id="4-模型描述"><a href="#4-模型描述" class="headerlink" title="4 模型描述"></a>4 模型描述</h2><p>回想2中预测房子价格的例子，根据已有的数据集，我们需要预测面积为1250的房子的价值。这是一个监督学习——对于数据集中的房子我们知道它们的面积和价格，这是一个回归问题——我们预测一个具体的数值输出。另一种常见的监督学习问题——分类问题，我们用它来预测离散值输出。<br>在建模过程中的符号如下：<br>m:表示训练样本的数量。<br>x’s:输入变量/特征。<br>y’s:输出变量/标签变量。<br>(x,y)表示一个训练样本。</p>
<script type="math/tex; mode=display">(x^{(i)},y^{(i)})</script><p>表示第i个训练样本，上标i是训练集的一个索引。<br>在上图中h表示假设函数，它的作用是把房子的大小作为输入变量，输出为相应房子的预测y值。h是一个从x到y的映射。我们将h表示为</p>
<script type="math/tex; mode=display">h_\theta(x)=\theta_0+\theta_1*x,缩写为 h(x)</script><p><img src="/images/机器学习/模型描述1.png" alt="模型描述1"><br>从表达式可以看出，y是一个关于x的线性函数(这是因为我们要从最基础的拟合开始讲起)。我们将从这个例子开始，先拟合线性函数，然后在此基础上，最终处理更加复杂的模型，以及学习更复杂的学习算法。这个模型被称为线性回归，这个例子为一元线性回归(单变量线性回归)。</p>
<h2 id="5-代价函数"><a href="#5-代价函数" class="headerlink" title="5 代价函数"></a>5 代价函数</h2><h3 id="5-1-代价函数的定义"><a href="#5-1-代价函数的定义" class="headerlink" title="5.1 代价函数的定义"></a>5.1 代价函数的定义</h3><p>在这一节中，我们将定义代价函数的概念，帮助我们弄清楚如何把最有可能的直线与我们的数据相拟合。</p>
<script type="math/tex; mode=display">h_\theta(x)=\theta_0+\theta_1*x,缩写为 h(x)</script><script type="math/tex; mode=display">\theta_{i's}为模型参数$$，我们选择不同的θ值，就会得到不同的假设函数。
![代价函数1](/images/机器学习/代价函数1.png)
我们要做的就是得出θ0和θ1这两个参数的值，来让假设函数表示的直线尽量地与这些数据点很好的拟合。那么我们如何得出θ0和θ1的值来使它很好地拟合数据呢？我们要去选择能使h(x)也就是输入x时我们预测的值最接近该样本对应的y值的参数θ0和θ1。
在线性回归中，我们要解决的是一个最小化问题，使得下式的值最小。
$$minimize\frac{1}{2m}\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2</script><p>我们使用(x^(i),y^(i))表示第i个样本。m指的是训练集的样本容量。1/m 表示m个样本方差的均值，2是为了方便后面求导，其实是可以取任意实数，最终都会得出相同的θ0值和相同的θ1值，使得上式取得最小值。<br>我们将上述值定义成一个代价函数(cost function)如下：</p>
<script type="math/tex; mode=display">J(\theta_0,\theta_1)=\frac{1}{2m}\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2</script><p>其中，</p>
<script type="math/tex; mode=display">h_\theta(x)=\theta_0+\theta_1*x</script><p>代价函数也被称作平方误差函数(Squard error function)，它可能是解决回归问题最常用的手段了。</p>
<h3 id="5-2-代价函数的作用"><a href="#5-2-代价函数的作用" class="headerlink" title="5.2 代价函数的作用"></a>5.2 代价函数的作用</h3><p><img src="/images/机器学习/代价函数2.png" alt="代价函数2"><br>实际上这包含了两个关键函数：<br>第一个是假设函数hθ(x),对于给定的θ，这是一个关于x的函数。<br>第二个是代价函数J(θ1)，是关于参数θ1的函数，它控制着h中直线的斜率。<br>当我们假设θ1=1时，我们求J(θ1)的值。</p>
<script type="math/tex; mode=display">J(\theta_1)=\frac{1}{2m}\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2</script><script type="math/tex; mode=display">J(\theta_1)=\frac{1}{2m}\sum_{i=1}^{m}(\theta_1x^{(i)}-y^{(i)})^2</script><script type="math/tex; mode=display">J(\theta_1)=\frac{1}{2m}0^{2}+0^{2}+0^{2}=0^2</script><p>上述结果是在下图数据集的基础上得到的。<br><img src="/images/机器学习/代价函数3.png" alt="代价函数3"><br>同理我们可以计算当θ1=0.5时，J(0.5)=7/12。当θ1=0时，J(0)=7/3。最终J(θ1)的函数图像如下：<br><img src="/images/机器学习/代价函数4.png" alt="代价函数4"><br>对于每个θ1，我们可以得到一个假设函数h，也可以得到损失函数J在θ1处的取值J(θ1)。优化算法的目标是我们通过选择不同的θ1，获得最小的J(θ1)，这就是线性回归的目标函数。在上图中，当θ1=1时，损失函数取得最小值。</p>
<h3 id="5-3-代价函数的作用-plus"><a href="#5-3-代价函数的作用-plus" class="headerlink" title="5.3 代价函数的作用-plus"></a>5.3 代价函数的作用-plus</h3><p>在上面的讨论中，为了简化问题，我们将θ0=0，现在我们保留全部参数θ0和θ1。则它的损失函数如下：<br><img src="/images/机器学习/代价函数5.png" alt="代价函数5"><br>代价函数最小的点对应着更好的假设函数。</p>
<h2 id="6-梯度下降"><a href="#6-梯度下降" class="headerlink" title="6 梯度下降"></a>6 梯度下降</h2><p>梯度下降是很常用的算法，它不仅悲用在线性回归上，还被广泛用于机器学习的众多领域。我们可以使用梯度下降的方法去最小化线性回归的代价函数J，或是其他函数。<br>我们有一个函数J(θ0，θ1)，我们的目标是最小化J。<br>梯度下降的思路：<br>1)先给定θ0和θ1的初始值。初值到底是多少其实并不重要，但是一般将θ0设为0，θ1也设为0。<br>2)不停地一点点地改变θ0和θ1，来使得J变小。直到我们找到J的最小值，或者局部最小值。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" rel="tag"># 数据挖掘</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/11/01/%E5%85%B4%E8%B6%A3/%E7%94%9F%E7%89%A9%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" rel="prev" title="生物数据挖掘学习">
      <i class="fa fa-chevron-left"></i> 生物数据挖掘学习
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-什么是机器学习"><span class="nav-number">1.</span> <span class="nav-text">1 什么是机器学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-机器学习的定义"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 机器学习的定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-学习算法"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 学习算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-监督学习"><span class="nav-number">2.</span> <span class="nav-text">2 监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-回归问题"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 回归问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-分类问题"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 分类问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-总结"><span class="nav-number">2.3.</span> <span class="nav-text">2.3 总结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-无监督学习"><span class="nav-number">3.</span> <span class="nav-text">3 无监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-聚类"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 聚类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-鸡尾酒会算法"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 鸡尾酒会算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-模型描述"><span class="nav-number">4.</span> <span class="nav-text">4 模型描述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-代价函数"><span class="nav-number">5.</span> <span class="nav-text">5 代价函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-代价函数的定义"><span class="nav-number">5.1.</span> <span class="nav-text">5.1 代价函数的定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-代价函数的作用"><span class="nav-number">5.2.</span> <span class="nav-text">5.2 代价函数的作用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-代价函数的作用-plus"><span class="nav-number">5.3.</span> <span class="nav-text">5.3 代价函数的作用-plus</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-梯度下降"><span class="nav-number">6.</span> <span class="nav-text">6 梯度下降</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Monica</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">54</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">28</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Monica</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
